{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc510ae",
   "metadata": {},
   "source": [
    "tldr - This data has been downloaded from my \"saved jobs\" on LinkedIn. This notebook helps process and sort the data into our groups for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64790c1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "I'm running an experiment on how well two different resume's perform. Does a professionally written resume perform better than one I've written myself?\t\t\t\n",
    "\n",
    "# Hypothesis\n",
    "$H_{0} = \\text{The resume and cover letter provided by Haley Stock perform the same as my own self-written resume and cover letter.}$\n",
    "\n",
    "$H_{a} = \\text{The professionally-written resume and cover letter have a different interview invitation rate than self-written resume and cover letter.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8b8a2",
   "metadata": {},
   "source": [
    "| Name                       | Definition                                                                                                   | Example Format | P1   | P2 (from detectable difference below) |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------|----------------|------|----------------------------------------|\n",
    "| Interview Invitation Rate  | This is the percent of applications that receive an interview invite. It shows how interested companies are in my resume. | 0.50%         | 8%   | 13%                                    |\n",
    "| Application Response Rate  | This is the percent of applications that receive a rejection/interview invite within 48 hrs. It shows how confident companies are in my qualifications. | 1%             |      |                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5fda4e",
   "metadata": {},
   "source": [
    "# Data Collection Process\n",
    "**LinkedIn:** I searched for \"data\" and remote in US roles. I then saved the roles that met the criteria below to a csv (via LinkedIn's data request form)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e6da3",
   "metadata": {},
   "source": [
    "# Inclusion Criteria\n",
    "Here are the kinds of jobs I'm interested in. I'm going to include these roles in the experiment based on the logic listed below.\n",
    "\n",
    "| **Category**            | **Details**                                                                                                                                                          |\n",
    "|:------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Location**            | Remote work only                                                                                                                                                     |\n",
    "| **Minimum Job Roles**   | Data Scientist, Senior Data/Product Analyst, or Manager/Lead<br>No Applied Scientist, Decision Science, Analytics Engineer, or Researcher roles (significantly different than my experience would allow)<br>No Product Manager roles (not interested in product management)<br>No Director level roles (largely above my level) |\n",
    "| **Type**                | Full time and contracted                                                                                                                                             |\n",
    "| **Duplicate Job Roles** | Sometimes companies post multiple versions of a job (by location or reposts after a few weeks have gone by). Will do my best to dedupe these in the final \"saved jobs\" list. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63981e",
   "metadata": {},
   "source": [
    "# Potential Pitfalls and Adjustments\n",
    "1) *Cutting sample collection short.* **Discussion:** See power analysis below. Peer review pending.\n",
    "2) *Confirming random assignment.* **Discussion:** Randomizing at cluster level (company + job title).\n",
    "3) *Random assignment fails to equally distribute \"heavy\" segments across A/B.* **Discussion:** Equally distribute the following segments and assess post-assignment:\n",
    "   - Recency of job posting\n",
    "   - \"Repeat\" companies (see \"8)\" below)\n",
    "4) *Ensure the Ceteris Parabus assumption* (that is, ensure all else is same between treatment/control besides the treatment). **Discussion:** Use the exact resume and cover letter provided for both.\n",
    "5) *Cross-contamination for treatment and control groups.* **Discussion:** I don't think we'll have to worry about this, unless a recruiter leaves one company and goes to another.\n",
    "6) *Multiple comparisons can lead to higher false positive rate.* **Discussion:** Only making one comparison -- professionally written resume vs. self-written resume.\n",
    "7) *Simpson's paradox due to graduated roll-outs.* **Discussion:** I'm only performing one testing period, so this point is moot. Could simply look at final period if so.\n",
    "8) *Primacy or novelty effect.* **Discussion:** This could be a problem, if I previously applied for a role with a company before conducting the experiment. I can adjust for this by running the experiment longer, but that's not really helpful given my current situation. Instead, I will include a category segment across treatment/control for repeat and new companies.\n",
    "    - \"Repeat\" = companies that I've applied to before. I'll attempt to equally distribute these during assignment.\n",
    "    - \"New\" = companies that I have not applied to before. I'll attempt to equally distribute these during assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df2ab6",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d38d3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = \"\"\"\n",
    "To-Do:\n",
    "- sortingHat: make it sort at the company level and not just job title.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbaeabdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/resume_experiment/data/modified_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import FileLink\n",
    "\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit <--this didn't work, because some groupings only have 1 job role.\n",
    "\n",
    "#import the job sampling data\n",
    "data_folder = \"/notebooks/resume_experiment/data\"\n",
    "dataf = \"modified_data.csv\"\n",
    "data_file = os.path.join(data_folder, dataf)\n",
    "\n",
    "print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37bfa8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role_title</th>\n",
       "      <th>company</th>\n",
       "      <th>date_saved</th>\n",
       "      <th>posting_url</th>\n",
       "      <th>days_since_post</th>\n",
       "      <th>is_repeat_company</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>job_posted_pin</th>\n",
       "      <th>role_cat</th>\n",
       "      <th>sorting_hat_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>11/5/24, 9:02 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4032373471</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>7days</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1.0_7days_Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Senior Manager, Product Insights</td>\n",
       "      <td>Included Health</td>\n",
       "      <td>11/8/24, 8:38 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4000281134</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/9/2024</td>\n",
       "      <td>7days</td>\n",
       "      <td>Manager</td>\n",
       "      <td>0.0_7days_Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Senior Risk Data Analyst</td>\n",
       "      <td>Sardine</td>\n",
       "      <td>11/8/24, 8:37 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4035291235</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/1/2024</td>\n",
       "      <td>14days</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.0_14days_Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>J.D. Power</td>\n",
       "      <td>11/8/24, 8:46 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4053921191</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/9/2024</td>\n",
       "      <td>7days</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.0_7days_Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Sr. Analyst Relations Manager</td>\n",
       "      <td>Databricks</td>\n",
       "      <td>11/9/24, 10:35 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/3968640351</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/11/2024</td>\n",
       "      <td>7days</td>\n",
       "      <td>Manager</td>\n",
       "      <td>0.0_7days_Manager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           role_title          company         date_saved  \\\n",
       "231                    Data Scientist           Stripe   11/5/24, 9:02 AM   \n",
       "296  Senior Manager, Product Insights  Included Health   11/8/24, 8:38 AM   \n",
       "280          Senior Risk Data Analyst          Sardine   11/8/24, 8:37 AM   \n",
       "276             Senior Data Scientist       J.D. Power   11/8/24, 8:46 AM   \n",
       "90      Sr. Analyst Relations Manager       Databricks  11/9/24, 10:35 AM   \n",
       "\n",
       "                                      posting_url  days_since_post  \\\n",
       "231  http://www.linkedin.com/jobs/view/4032373471              7.0   \n",
       "296  http://www.linkedin.com/jobs/view/4000281134              6.0   \n",
       "280  http://www.linkedin.com/jobs/view/4035291235             14.0   \n",
       "276  http://www.linkedin.com/jobs/view/4053921191              6.0   \n",
       "90   http://www.linkedin.com/jobs/view/3968640351              4.0   \n",
       "\n",
       "     is_repeat_company date_posted job_posted_pin        role_cat  \\\n",
       "231                1.0   11/8/2024          7days  Data Scientist   \n",
       "296                0.0   11/9/2024          7days         Manager   \n",
       "280                0.0   11/1/2024         14days    Data Analyst   \n",
       "276                0.0   11/9/2024          7days  Data Scientist   \n",
       "90                 0.0  11/11/2024          7days         Manager   \n",
       "\n",
       "              sorting_hat_col  \n",
       "231  1.0_7days_Data Scientist  \n",
       "296         0.0_7days_Manager  \n",
       "280   0.0_14days_Data Analyst  \n",
       "276  0.0_7days_Data Scientist  \n",
       "90          0.0_7days_Manager  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role_title</th>\n",
       "      <th>company</th>\n",
       "      <th>date_saved</th>\n",
       "      <th>posting_url</th>\n",
       "      <th>days_since_post</th>\n",
       "      <th>is_repeat_company</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>job_posted_pin</th>\n",
       "      <th>role_cat</th>\n",
       "      <th>sorting_hat_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [role_title, company, date_saved, posting_url, days_since_post, is_repeat_company, date_posted, job_posted_pin, role_cat, sorting_hat_col]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(data_file, low_memory=False)\n",
    "raw_df = raw_df.dropna(axis=0,subset=\"role_title\")\n",
    "raw_df = raw_df.loc[raw_df.loc[:,'DELETE Row'] != True]\n",
    "raw_df['sorting_hat_col'] = raw_df['is_repeat_company'].astype('str')+\"_\"+raw_df['job_posted_pin']+\"_\"+raw_df['role_cat']\n",
    "raw_df = raw_df.drop([\"Applied Jobs Check\", \"DELETE Row\", \"Check Unique Job/Co\"], axis=1)\n",
    "\n",
    "display(raw_df.sample(5))\n",
    "display(raw_df.loc[raw_df.loc[:,\"sorting_hat_col\"].isnull()].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f5359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#build a list of the companies that are in our dataset. include new vs. repeat as a dimension\n",
    "companies = raw_df.copy().filter(['company','is_repeat_company','days_since_post'])\n",
    "companies['counts'] = 1\n",
    "agg_mets = {'counts':\"count\", 'days_since_post':\"mean\"}\n",
    "companies = companies.groupby(['company','is_repeat_company']).agg(agg_mets).reset_index()\n",
    "display(companies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6163b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ensure company lists are mutually exclusive\n",
    "new_companies = set(new_cluster['company'])\n",
    "repeat_companies = set(repeat_cluster['company'])\n",
    "\n",
    "is_mutually_exclusive = new_companies.isdisjoint(repeat_cluster)\n",
    "assert is_mutually_exclusive, \"Companies overlapp between new and repeat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "561cd54d-7956-406f-91b5-4909b52ab156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sortingHat(data, sampling_col, stratification_col, split_percent=0.5, seed=42):\n",
    "    #Create a list of unique stratification segments.\n",
    "    uni_strats = data[stratification_col].unique()\n",
    "    \n",
    "    #Setting our seed\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Create a new column for the splits\n",
    "    data['ab_split'] = np.nan\n",
    "    \n",
    "    #Look at every segment; pull out the rows for each segment and then assign them a 1 or 0 randomly.\n",
    "    for s in uni_strats:\n",
    "        sorting_df = data.loc[data.loc[:,stratification_col]==s]\n",
    "        nrows = sorting_df.shape[0]\n",
    "        split = pd.Series(rng.integers(low=0,high=1, size=nrows, endpoint=True), index=sorting_df.index)\n",
    "        split.name = \"ab_split\"\n",
    "        \n",
    "        # Assign the split values back to the DataFrame\n",
    "        data.loc[sorting_df.index, 'ab_split'] = split\n",
    "        \n",
    "    #display(data.filter(['ab_split','role_title']).groupby('ab_split').count())\n",
    "        \n",
    "    return(data)\n",
    "\n",
    "df = sortingHat(raw_df, 'company', 'sorting_hat_col', split_percent=0.5)\n",
    "split_path = os.path.join(data_folder,\"split.csv\")\n",
    "df.to_csv(split_path)\n",
    "#print(len(grps))\n",
    "#print(grps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e679d7b7-20ee-40bb-9862-a6bd2242d2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display(FileLink('./split.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
