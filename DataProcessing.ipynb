{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc510ae",
   "metadata": {},
   "source": [
    "This data has been downloaded from my \"saved jobs\" on LinkedIn. This notebook helps process and sort the data into our groups for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64790c1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "I'm running an experiment on how well two different resume's perform. Does a professionally written resume perform better than one I've written myself?\t\t\t\n",
    "\n",
    "# Hypothesis\n",
    "$H_{0} = \\text{The resume and cover letter provided by Haley Stock perform the same as my own self-written resume and cover letter.}$\n",
    "\n",
    "$H_{a} = \\text{The professionally-written resume and cover letter have a different interview invitation rate than self-written resume and cover letter.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8b8a2",
   "metadata": {},
   "source": [
    "| Name                       | Definition                                                                                                   | Example Format | P1   | P2 (from detectable difference below) |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------|----------------|------|----------------------------------------|\n",
    "| Interview Invitation Rate  | This is the percent of applications that receive an interview invite. It shows how interested companies are in my resume. | 0.50%         | 8%   | 13%                                    |\n",
    "| Application Response Rate  | This is the percent of applications that receive a rejection/interview invite within 48 hrs. It shows how confident companies are in my qualifications. | 1%             |      |                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5fda4e",
   "metadata": {},
   "source": [
    "# Data Collection Process\n",
    "**LinkedIn:** I searched for \"data\" and remote in US roles. I then saved the roles that met the criteria below to a csv (via LinkedIn's data request form)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e6da3",
   "metadata": {},
   "source": [
    "# Inclusion Criteria\n",
    "Here are the kinds of jobs I'm interested in. I'm going to include these roles in the experiment based on the logic listed below.\n",
    "\n",
    "| **Category**            | **Details**                                                                                                                                                          |\n",
    "|:------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Location**            | Remote work only                                                                                                                                                     |\n",
    "| **Minimum Job Roles**   | Data Scientist, Senior Data/Product Analyst, or Manager/Lead<br>No Applied Scientist, Decision Science, Analytics Engineer, or Researcher roles (significantly different than my experience would allow)<br>No Product Manager roles (not interested in product management)<br>No Director level roles (largely above my level) |\n",
    "| **Type**                | Full time and contracted                                                                                                                                             |\n",
    "| **Duplicate Job Roles** | Sometimes companies post multiple versions of a job (by location or reposts after a few weeks have gone by). Will do my best to dedupe these in the final \"saved jobs\" list. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63981e",
   "metadata": {},
   "source": [
    "# Potential Pitfalls and Adjustments\n",
    "1) *Cutting sample collection short.* **Discussion:** See power analysis below. Peer review pending.\n",
    "2) *Confirming random assignment.* **Discussion:** Randomizing at cluster level (company + job title).\n",
    "3) *Random assignment fails to equally distribute \"heavy\" segments across A/B.* **Discussion:** Equally distribute the following segments and assess post-assignment:\n",
    "   - Recency of job posting\n",
    "   - \"Repeat\" companies (see \"8)\" below)\n",
    "4) *Ensure the Ceteris Parabus assumption* (that is, ensure all else is same between treatment/control besides the treatment). **Discussion:** Use the exact resume and cover letter provided for both.\n",
    "5) *Cross-contamination for treatment and control groups.* **Discussion:** I don't think we'll have to worry about this, unless a recruiter leaves one company and goes to another.\n",
    "6) *Multiple comparisons can lead to higher false positive rate.* **Discussion:** Only making one comparison -- professionally written resume vs. self-written resume.\n",
    "7) *Simpson's paradox due to graduated roll-outs.* **Discussion:** I'm only performing one testing period, so this point is moot. Could simply look at final period if so.\n",
    "8) *Primacy or novelty effect.* **Discussion:** This could be a problem, if I previously applied for a role with a company before conducting the experiment. I can adjust for this by running the experiment longer, but that's not really helpful given my current situation. Instead, I will include a category segment across treatment/control for repeat and new companies.\n",
    "    - \"Repeat\" = companies that I've applied to before. I'll attempt to equally distribute these during assignment.\n",
    "    - \"New\" = companies that I have not applied to before. I'll attempt to equally distribute these during assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df2ab6",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d38d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/resume_experiment\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbaeabdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/resume_experiment/data/res_xp_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#import the job sampling data\n",
    "data_folder = \"/notebooks/resume_experiment/data\"\n",
    "dataf = \"res_xp_data.csv\"\n",
    "data_file = os.path.join(data_folder, dataf)\n",
    "\n",
    "print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bfa8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role_title</th>\n",
       "      <th>company</th>\n",
       "      <th>date_saved</th>\n",
       "      <th>posting_url</th>\n",
       "      <th>days_since_post</th>\n",
       "      <th>is_repeat_company</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>Applied Jobs Check</th>\n",
       "      <th>DELETE Row</th>\n",
       "      <th>Check Unique Job/Co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analytics Manager</td>\n",
       "      <td>Panasonic North America</td>\n",
       "      <td>11/9/24, 10:32 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4022291235</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arity- Data Scientist Senior Manager - Arity</td>\n",
       "      <td>Arity</td>\n",
       "      <td>11/9/24, 10:42 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4064869221</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Lead Associate</td>\n",
       "      <td>Protective Life</td>\n",
       "      <td>11/9/24, 10:31 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4040898277</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/1/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Senior Manager</td>\n",
       "      <td>CLARA Analytics</td>\n",
       "      <td>11/12/24, 11:06 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4074304576</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/12/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Apollo GraphQL</td>\n",
       "      <td>11/9/24, 10:49 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4070255734</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Product Data Scientist</td>\n",
       "      <td>Propel, Inc</td>\n",
       "      <td>11/9/24, 10:49 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4068137912</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Staff Data Scientist (Remote, US)</td>\n",
       "      <td>Grafana Labs</td>\n",
       "      <td>11/9/24, 10:31 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4034580358</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist, Core Products</td>\n",
       "      <td>Coalition, Inc.</td>\n",
       "      <td>11/9/24, 10:29 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4025947473</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/1/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>InStride</td>\n",
       "      <td>11/9/24, 10:42 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4064739945</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/8/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Senior Manager - Data Science</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>11/9/24, 10:32 AM</td>\n",
       "      <td>http://www.linkedin.com/jobs/view/4041683824</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/1/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      role_title                  company  \\\n",
       "0                         Data Analytics Manager  Panasonic North America   \n",
       "1   Arity- Data Scientist Senior Manager - Arity                    Arity   \n",
       "2                    Data Science Lead Associate          Protective Life   \n",
       "3                    Data Science Senior Manager          CLARA Analytics   \n",
       "4                            Lead Data Scientist           Apollo GraphQL   \n",
       "5                  Senior Product Data Scientist              Propel, Inc   \n",
       "6              Staff Data Scientist (Remote, US)             Grafana Labs   \n",
       "8                  Data Scientist, Core Products          Coalition, Inc.   \n",
       "10                              Sr. Data Analyst                 InStride   \n",
       "11                 Senior Manager - Data Science                   McAfee   \n",
       "\n",
       "            date_saved                                   posting_url  \\\n",
       "0    11/9/24, 10:32 AM  http://www.linkedin.com/jobs/view/4022291235   \n",
       "1    11/9/24, 10:42 AM  http://www.linkedin.com/jobs/view/4064869221   \n",
       "2    11/9/24, 10:31 AM  http://www.linkedin.com/jobs/view/4040898277   \n",
       "3   11/12/24, 11:06 AM  http://www.linkedin.com/jobs/view/4074304576   \n",
       "4    11/9/24, 10:49 AM  http://www.linkedin.com/jobs/view/4070255734   \n",
       "5    11/9/24, 10:49 AM  http://www.linkedin.com/jobs/view/4068137912   \n",
       "6    11/9/24, 10:31 AM  http://www.linkedin.com/jobs/view/4034580358   \n",
       "8    11/9/24, 10:29 AM  http://www.linkedin.com/jobs/view/4025947473   \n",
       "10   11/9/24, 10:42 AM  http://www.linkedin.com/jobs/view/4064739945   \n",
       "11   11/9/24, 10:32 AM  http://www.linkedin.com/jobs/view/4041683824   \n",
       "\n",
       "    days_since_post  is_repeat_company date_posted Applied Jobs Check  \\\n",
       "0               7.0                0.0   11/8/2024                NaN   \n",
       "1               7.0                0.0   11/8/2024                NaN   \n",
       "2              14.0                0.0   11/1/2024                NaN   \n",
       "3               3.0                0.0  11/12/2024                NaN   \n",
       "4               7.0                0.0   11/8/2024                NaN   \n",
       "5               7.0                0.0   11/8/2024                NaN   \n",
       "6               7.0                1.0   11/8/2024                NaN   \n",
       "8              14.0                0.0   11/1/2024                NaN   \n",
       "10              7.0                0.0   11/8/2024                NaN   \n",
       "11             14.0                1.0   11/1/2024                NaN   \n",
       "\n",
       "   DELETE Row  Check Unique Job/Co  \n",
       "0         NaN                    2  \n",
       "1         NaN                    1  \n",
       "2         NaN                    1  \n",
       "3         NaN                    1  \n",
       "4         NaN                    1  \n",
       "5         NaN                    1  \n",
       "6         NaN                    1  \n",
       "8         NaN                    1  \n",
       "10        NaN                    1  \n",
       "11        NaN                    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(data_file, low_memory=False)\n",
    "raw_df = raw_df.loc[raw_df.loc[:,'DELETE Row'] != True]\n",
    "display(raw_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd9f5359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 4)\n"
     ]
    }
   ],
   "source": [
    "#build a list of the companies that are in our dataset. include new vs. repeat as a dimension\n",
    "companies = raw_df.copy().filter(['company','is_repeat_company','days_since_post'])\n",
    "companies['counts'] = 1\n",
    "agg_mets = {'counts':\"count\", 'days_since_post':\"mean\"}\n",
    "companies = companies.groupby(['company','is_repeat_company']).agg(agg_mets).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21ab1f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 4)\n",
      "(24, 4)\n"
     ]
    }
   ],
   "source": [
    "#Assign companies to clusters\n",
    "new_cluster = companies.loc[companies.loc[:,'is_repeat_company']==False]\n",
    "print(new_cluster.shape)\n",
    "\n",
    "repeat_cluster = companies.loc[companies.loc[:,'is_repeat_company']==True]\n",
    "print(repeat_cluster.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6163b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m repeat_companies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(repeat_cluster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m is_mutually_exclusive \u001b[38;5;241m=\u001b[39m new_companies\u001b[38;5;241m.\u001b[39misdisjoint(repeat_cluster)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ensure company lists are mutually exclusive\n",
    "new_companies = set(new_cluster['company'])\n",
    "repeat_companies = set(repeat_cluster['company'])\n",
    "\n",
    "is_mutually_exclusive = new_companies.isdisjoint(repeat_cluster)\n",
    "assert False, raise Exception(\"Companies overlapp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly assign clusters to groups\n",
    "\n",
    "for c in clusters:\n",
    "    generate random number between 1,2\n",
    "    if random number == 1:\n",
    "        assign c to control\n",
    "    elif random number == 2:\n",
    "        assign c to treatment\n",
    "\n",
    "save the assignment to a file for control\n",
    "save the assignment to a file for treatment\n",
    "tell me how many jobs are in each treatment and control cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
